import os
import pickle
import google.generativeai as genai
import json
import numpy as np
import pandas as pd
import faiss
from flask import Blueprint, request, jsonify, render_template
from langchain.schema import Document
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS
import time


chatbot_bp = Blueprint('chatbot', __name__)

# ğŸ”¹ ê²½ë¡œ ì„¤ì •
FAISS_INDEX_DIR = "cos/ingredients_faiss_index"
PICKLE_VECTORSTORE_PATH = os.path.join(FAISS_INDEX_DIR, "vectorstore.pkl")
CSV_PATH = "cos/data/paulas_choice_ingredients_all_v2.csv"


# ğŸ”¹ API í‚¤ ì„¤ì •
gemini_api_key = "you api key"
genai.configure(api_key=gemini_api_key)

#ğŸ”¹ HuggingFace ì„ë² ë”© ëª¨ë¸ ë¡œë“œ
def load_embedding():
    return HuggingFaceEmbeddings(model_name="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2")

# ğŸ”¹ FAISS ë²¡í„° ì €ì¥ì†Œ ë¡œë“œ
def load_vectorstore(embedding_model):
    if os.path.exists(PICKLE_VECTORSTORE_PATH):
        with open(PICKLE_VECTORSTORE_PATH, "rb") as f:
            vectorstore = pickle.load(f)
    else:
        df = pd.read_csv(CSV_PATH)
        df['ingredients'] = df['ingredients'].fillna("")

        documents = [Document(page_content=row['ingredients'], metadata={"source": row['ingredients']}) for _, row in df.iterrows()]
        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
        splits = text_splitter.split_documents(documents)
        
        vectorstore = FAISS.from_documents(splits, embedding=embedding_model)

        with open(PICKLE_VECTORSTORE_PATH, "wb") as f:
            pickle.dump(vectorstore, f)

    return vectorstore

# ğŸ”¹ ëª¨ë¸ ë° ë²¡í„° ì €ì¥ì†Œ ì´ˆê¸°í™”
embedding_model = load_embedding()
vectorstore = load_vectorstore(embedding_model)
gemini_model = genai.GenerativeModel('gemini-1.5-flash')

def generate_ai_response(prompt):
    """Gemini ëª¨ë¸ì˜ ì„±ëŠ¥ ìµœì í™”ë¥¼ ìœ„í•œ AI ì‘ë‹µ ìƒì„± í•¨ìˆ˜"""
    try:
        response = gemini_model.generate_content(
            prompt,
            generation_config={
                "temperature": 0.7,  # âœ… ì°½ì˜ì„± ì¡°ì ˆ (ë‚®ì„ìˆ˜ë¡ ì¼ê´€ëœ ë‹µë³€ ì œê³µ)
                "top_p": 0.9,  # âœ… ì‘ë‹µ í’ˆì§ˆ í–¥ìƒ (ìµœê³  í™•ë¥ ì˜ ë‹µë³€ ì„ íƒ)
                "frequency_penalty": 0.3,  # âœ… ë™ì¼í•œ ë‹¨ì–´ ë°˜ë³µ ë°©ì§€
                "presence_penalty": 0.2   # âœ… ìƒˆë¡œìš´ ì •ë³´ ìƒì„± ìœ ë„
            }
        )
        
        # âœ… ì‘ë‹µì´ ì—¬ëŸ¬ ê°œì¼ ê²½ìš°, ê°€ì¥ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ë‹µë³€ì„ ì„ íƒ
        if response and response.candidates:
            for candidate in response.candidates:
                if candidate.content and candidate.content.parts:
                    return candidate.content.parts[0].text.strip()

        return "âš ï¸ AI ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”."

    except Exception as e:
        return f"âš ï¸ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"


# ğŸ”¹ RAG ê¸°ë°˜ ë‹µë³€ ìƒì„±
def rag_chatbot(question):

    # "ì±—ë´‡ ë¶„ì„"ì— ëŒ€í•œ ì§ˆë¬¸ì´ ë“¤ì–´ì˜¨ ê²½ìš°
    if "ì±—ë´‡ ë¶„ì„" in question:
        return 'ì±—ë´‡ ì‘ë‹µ ì‹œê°„ ë¶„ì„ì„ ë³´ë ¤ë©´ <a href="http://127.0.0.1:5000/chart" target="_blank">ì—¬ê¸°</a>ë¥¼ í´ë¦­í•˜ì„¸ìš”!'

    retrieved_docs = vectorstore.similarity_search(question, k=5)
    context_texts = "\n".join([doc.page_content for doc in retrieved_docs])

    prompt = f"""

[ì°¸ê³  ë¬¸ì„œ]
{context_texts}

[ì§ˆë¬¸]
{question}

[ì‘ë‹µ ê°€ì´ë“œ]
- ì§ˆë¬¸ì— **"í™”ì¥í’ˆ ì¶”ì²œ"**ì´ í¬í•¨ë˜ë©´, ëª¨ë“  ì‘ë‹µì˜ **ì²« ì¤„**ì—  
  **"â— íŠ¹ì • í™”ì¥í’ˆ ì¶”ì²œì€ ì–´ë µìŠµë‹ˆë‹¤. ëŒ€ì‹ , ì„±ë¶„ ì¶”ì²œì´ ê°€ëŠ¥í•©ë‹ˆë‹¤. ì›í•˜ëŠ” ì„±ë¶„ì´ë‚˜ í”¼ë¶€ ê³ ë¯¼ì„ ë§ì”€í•´ì£¼ì„¸ìš”!"** ë¥¼ ì¶”ê°€í•˜ì„¸ìš”.
- ì§ˆë¬¸ì— "í™”ì¥í’ˆ"ì´ë¼ëŠ” ë‹¨ì–´ê°€ í¬í•¨ë˜ë©´, ì œí’ˆ ì¶”ì²œ ëŒ€ì‹  **ì„±ë¶„ ì •ë³´**ì™€ **í”¼ë¶€ íƒ€ì…** ê´€ë ¨ ë‚´ìš©ì„ ì¤‘ì‹¬ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”.
- ì§ˆë¬¸ì´ **íŠ¹ì • ì„±ë¶„**(ì˜ˆ: íˆì•Œë£¨ë¡ ì‚°, í‹°íŠ¸ë¦¬ ì˜¤ì¼ ë“±)ì— ëŒ€í•œ ê²ƒì´ë¼ë©´ **ê°œì¡°ì‹**ìœ¼ë¡œ ì •ë³´ë¥¼ ì œê³µí•˜ì„¸ìš”.  
- ì§ˆë¬¸ì´ **í”¼ë¶€ ê³ ë¯¼**ì´ë‚˜ **ì‚¬ìš©ë²• ê´€ë ¨ ì¡°ì–¸**ì¸ ê²½ìš°ì—ëŠ” **ëŒ€í™”í˜• ë‹µë³€**ì„ ì œê³µí•˜ì„¸ìš”.
- **í•µì‹¬ ì •ë³´ë§Œ ì œê³µ**: ë¶ˆí•„ìš”í•œ ë‚´ìš©ì€ ìƒëµí•˜ê³ , ì¤‘ìš”í•œ í¬ì¸íŠ¸ë§Œ ê°•ì¡°í•©ë‹ˆë‹¤.
- **ëª©ë¡ í˜•ì‹ í™œìš©**: ì„±ë¶„ ì •ë³´ë‚˜ íš¨ê³¼ ë“±ì„ ë¦¬ìŠ¤íŠ¸ í˜•ì‹ìœ¼ë¡œ ì œê³µí•˜ì—¬ ê°€ë…ì„±ì„ ë†’ì´ì„¸ìš”.
- **ê°„ê²°í•œ ë¬¸ì¥ ì‚¬ìš©**: ë¬¸ì¥ì€ ìµœëŒ€ 1~2ê°œì˜ í•µì‹¬ í¬ì¸íŠ¸ë§Œ ë‹´ê³ , 7~10ì¤„ ì´ë‚´ë¡œ ìœ ì§€í•˜ì„¸ìš”.
- **ë¶ˆí•„ìš”í•œ ì„¸ë¶€ì‚¬í•­ ìƒëµ**: ê³¼ë„í•œ ë°°ê²½ ì„¤ëª…ì„ ì¤„ì´ê³ , í•µì‹¬ ë‚´ìš©ì— ì§‘ì¤‘í•˜ì„¸ìš”.
- **ëŒ€í™”í˜• ë‹µë³€**: ì¹œì ˆí•˜ë©´ì„œë„ í•µì‹¬ì ì¸ ì •ë³´ë¥¼ ë¹ ë¥´ê²Œ ì „ë‹¬í•˜ì„¸ìš”.


---

[ì§ˆë¬¸ ìœ í˜•ë³„ ì‘ë‹µ ë°©ì‹]

ğŸŸ¢ **ì§ˆë¬¸ì— íŠ¹ì • ì„±ë¶„ì´ í¬í•¨ëœ ê²½ìš°** (ì˜ˆ: "íˆì•Œë£¨ë¡ ì‚° íš¨ëŠ¥ì´ ë­ì•¼?")  
â†’ ì•„ë˜ í˜•ì‹ìœ¼ë¡œ ê°œì¡°ì‹ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”.

1ï¸âƒ£ **ì„±ë¶„ëª… (ì˜ë¬¸ëª…)**  
ğŸ”¹ **íš¨ê³¼**: ì£¼ìš” í”¼ë¶€ íš¨ëŠ¥ ìš”ì•½  
ğŸ”¹ **íŠ¹ì§•**: ì„±ë¶„ì˜ í•µì‹¬ì ì¸ ì—­í•   
ğŸ”¹ **í™œìš©**: ì–´ë–¤ ì œí’ˆì— í¬í•¨ë˜ëŠ”ì§€  
ğŸ”¹ **ì£¼ì˜ì‚¬í•­**: ì‚¬ìš© ì‹œ ì£¼ì˜í•  ì   

**[ì˜ˆì‹œ]**  
1ï¸âƒ£ **ì‚´ë¦¬ì‹¤ì‚° (Salicylic Acid)**  
ğŸ”¹ **íš¨ê³¼**: ê°ì§ˆ ì œê±°, ëª¨ê³µ ì²­ê²°, í”¼ì§€ ì¡°ì ˆ  
ğŸ”¹ **íŠ¹ì§•**: ì§€ìš©ì„± BHAë¡œ ëª¨ê³µ ì† ê¹Šì´ ì¹¨íˆ¬í•˜ì—¬ í”¼ì§€ ë¶„í•´  
ğŸ”¹ **í™œìš©**: ì—¬ë“œë¦„ ì „ìš© í´ë Œì €, í† ë„ˆ, ìŠ¤íŒŸ íŠ¸ë¦¬íŠ¸ë¨¼íŠ¸  
ğŸ”¹ **ì£¼ì˜ì‚¬í•­**: ê±´ì¡°í•¨ ìœ ë°œ ê°€ëŠ¥, ì €ë†ë„ë¶€í„° ì‚¬ìš© ê¶Œì¥  

---

ğŸŸ¡ **ì§ˆë¬¸ì´ ì¼ë°˜ì ì¸ í”¼ë¶€ ê³ ë¯¼ì´ë‚˜ ì¡°ì–¸ ìš”ì²­ì¸ ê²½ìš°**  
â†’ ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”í˜• ë‹µë³€ì„ ìƒì„±í•˜ì„¸ìš”.  
â†’ ë„ˆë¬´ ê¸°ê³„ì ì¸ ë‹µë³€ì´ ì•„ë‹ˆë¼ ì¹œì ˆí•˜ê²Œ ì„¤ëª…í•˜ì„¸ìš”.  

**[ì˜ˆì‹œ]**  
ğŸ™‹â€â™‚ï¸ "ìì™¸ì„  ì°¨ë‹¨ì œ(ì„ í¬ë¦¼)ì„ ê³ ë¥¼ ë•Œ ì–´ë–¤ ì ì„ ì£¼ì˜í•´ì•¼ í•˜ë‚˜ìš”?"  
ğŸ¤– "ì¢‹ì€ ì§ˆë¬¸ì´ì—ìš”! ì„ í¬ë¦¼ì„ ê³ ë¥¼ ë•ŒëŠ” SPFì™€ PA ë“±ê¸‰ì„ í™•ì¸í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•´ìš”.  
SPF 30~50 ì •ë„ê°€ ì¼ìƒìƒí™œì— ì í•©í•˜ê³ , PA+++ ì´ìƒì´ë©´ ìì™¸ì„  ì°¨ë‹¨ íš¨ê³¼ê°€ ì¢‹ì•„ìš”.  
ë˜í•œ, ì§€ì„± í”¼ë¶€ë¼ë©´ ì‚°ëœ»í•œ ì ¤ íƒ€ì…ì„, ê±´ì„± í”¼ë¶€ë¼ë©´ ë³´ìŠµë ¥ì´ ì¢‹ì€ í¬ë¦¼ íƒ€ì…ì„ ì„ íƒí•˜ëŠ” ê²Œ ì¢‹ì•„ìš”!"

ğŸ™‹â€â™‚ï¸ "ì—¬ë“œë¦„ í”¼ë¶€ì¸ë° ì–´ë–¤ ì„±ë¶„ì„ í”¼í•´ì•¼ í•˜ë‚˜ìš”?"  
ğŸ¤– "ì—¬ë“œë¦„ í”¼ë¶€ë¼ë©´ **ì½”ì½”ë„› ì˜¤ì¼, ë¯¸ë„¤ë„ ì˜¤ì¼, ë¼ë†€ë¦°** ê°™ì€ ì„±ë¶„ì€ í”¼í•˜ëŠ” ê²Œ ì¢‹ì•„ìš”.  
ì´ ì„±ë¶„ë“¤ì€ ëª¨ê³µì„ ë§‰ì•„ ì—¬ë“œë¦„ì„ ì•…í™”ì‹œí‚¬ ìˆ˜ ìˆê±°ë“ ìš”! ëŒ€ì‹  **ì‚´ë¦¬ì‹¤ì‚°, ë‚˜ì´ì•„ì‹ ì•„ë§ˆì´ë“œ** ê°™ì€ ì„±ë¶„ì´ ë„ì›€ì´ ë  ìˆ˜ ìˆì–´ìš”."

---

âš ï¸ **ì¶”ê°€ ì£¼ì˜ì‚¬í•­**  
- ë§Œì•½ ì§ˆë¬¸ì´ ì• ë§¤í•œ ê²½ìš°, "ì§ˆë¬¸ì„ ì¡°ê¸ˆ ë” êµ¬ì²´ì ìœ¼ë¡œ í•´ì£¼ì‹œë©´ ë” ì •í™•í•œ ì •ë³´ë¥¼ ì œê³µí•´ ë“œë¦´ ìˆ˜ ìˆì–´ìš”!" ë¼ê³  ë‹µë³€í•˜ì„¸ìš”.  
- ëŒ€í™”í˜• ë‹µë³€ì—ì„œë„ í•µì‹¬ ë‚´ìš©ì„ ë¹ ë¥´ê²Œ ì „ë‹¬í•  ìˆ˜ ìˆë„ë¡ ëª…í™•í•œ ì •ë³´ë¥¼ í¬í•¨í•˜ì„¸ìš”.  
- **í™”ì¥í’ˆ ë¸Œëœë“œë‚˜ ì œí’ˆëª…ì„ ì§ì ‘ ì¶”ì²œí•˜ì§€ ë§ê³ **, ì„±ë¶„ ì •ë³´ë§Œ ì œê³µí•˜ì„¸ìš”.  
- ëª¨ë“  ì„±ë¶„ì€ ê°œì¸ì˜ í”¼ë¶€ íƒ€ì…ì— ë”°ë¼ ë°˜ì‘ì´ ë‹¤ë¥¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- ìƒˆë¡œìš´ ì„±ë¶„ì„ ì‚¬ìš©í•  ë•ŒëŠ” ë°˜ë“œì‹œ íŒ¨ì¹˜ í…ŒìŠ¤íŠ¸ í›„ ì‚¬ìš©í•˜ì„¸ìš”.
- **ëª¨ë“  ì‘ë‹µì—ì„œ "í™”ì¥í’ˆ ì¶”ì²œ"ì´ í¬í•¨ëœ ê²½ìš° ì²« ì¤„ì— ë©”ì‹œì§€ë¥¼ ì¶”ê°€í•´ì•¼ í•©ë‹ˆë‹¤.**
- **"í™”ì¥í’ˆ ì¶”ì²œ" ìš”ì²­ì´ ë“¤ì–´ì˜¤ë©´ ì œí’ˆëª…ì´ ì•„ë‹Œ ì„±ë¶„ ì •ë³´ì™€ í”¼ë¶€ íƒ€ì… ì¤‘ì‹¬ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”.**

---
"â— íŠ¹ì • í™”ì¥í’ˆ ì¶”ì²œì€ ì–´ë µìŠµë‹ˆë‹¤. ëŒ€ì‹ , ì„±ë¶„ ì¶”ì²œì´ ê°€ëŠ¥í•©ë‹ˆë‹¤. ì›í•˜ëŠ” ì„±ë¶„ì´ë‚˜ í”¼ë¶€ ê³ ë¯¼ì„ ë§ì”€í•´ì£¼ì„¸ìš”!"
---
"""
   
    print(context_texts)
    
    # response = gemini_model.generate_content(prompt)
    # âœ… ê°œì„ ëœ Gemini API í˜¸ì¶œ
    answer = generate_ai_response(prompt)


    return answer



# ğŸ”¹ ì‘ë‹µ ì‹œê°„ ë¡œê·¸ ì €ì¥ í•¨ìˆ˜
LOG_FILE_PATH = "cos/response_time_log.json"

def log_response_time(response_time):
    """ì‘ë‹µ ì‹œê°„ì„ JSON íŒŒì¼ì— ì €ì¥í•˜ëŠ” í•¨ìˆ˜"""
    log_entry = {
        "timestamp": time.time(),
        "response_time": response_time
    }

    try:
        # ê¸°ì¡´ ë¡œê·¸ ë¶ˆëŸ¬ì˜¤ê¸° (íŒŒì¼ì´ ì—†ìœ¼ë©´ ë¹ˆ ë¦¬ìŠ¤íŠ¸)
        logs = []
        if os.path.exists(LOG_FILE_PATH):
            with open(LOG_FILE_PATH, "r") as f:
                logs = json.load(f)

        # ìƒˆ ë¡œê·¸ ì¶”ê°€
        logs.append(log_entry)

        # 100ê°œ ì´ìƒì˜ ë°ì´í„°ê°€ ìŒ“ì´ë©´ ì˜¤ë˜ëœ ë°ì´í„° ì œê±°
        if len(logs) > 100:
            logs.pop(0)

        # ë¡œê·¸ íŒŒì¼ ì—…ë°ì´íŠ¸
        with open(LOG_FILE_PATH, "w") as f:
            json.dump(logs, f, indent=4)

    except Exception as e:
        print(f"ë¡œê·¸ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")  # ì„œë²„ ë¡œê·¸ ì¶œë ¥


@chatbot_bp.route("/chatbot")
def chatbot_home():
    return render_template("input.html")  # ğŸ”¹ ì±—ë´‡ UI í˜ì´ì§€ (input.html ì‚¬ìš©)

# @chatbot_bp.route("/chatbot")
# def chatbot_home():
#     return render_template("result.html")  # ğŸ”¹ ì±—ë´‡ UI í˜ì´ì§€ (input.html ì‚¬ìš©)

@chatbot_bp.route("/ask", methods=["POST"])
def ask():
    data = request.json
    user_query = data.get("question", "").strip()

    if not user_query:
        return jsonify({"answer": "ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”!"})

    try:
        start_time = time.time()  # ì‹œì‘ ì‹œê°„ ê¸°ë¡
        response = rag_chatbot(user_query)  # âœ… Gemini API í˜¸ì¶œ
        end_time = time.time()  # ì¢…ë£Œ ì‹œê°„ ê¸°ë¡

        response_time = end_time - start_time  # ì‘ë‹µ ì‹œê°„ ê³„ì‚°
        log_response_time(response_time)  # âœ… ì‘ë‹µ ì‹œê°„ ë¡œê·¸ ì €ì¥
        
        return jsonify({"answer": response, "response_time": response_time})
    except Exception as e:
        return jsonify({"answer": f"ì˜¤ë¥˜ ë°œìƒ: {str(e)}"})

@chatbot_bp.route("/chart")
def show_chart():
    return render_template("charts.html")

@chatbot_bp.route("/response_time_chart_json")
def response_time_chart_json():
    """ì‘ë‹µ ì‹œê°„ ë°ì´í„°ë¥¼ JSONìœ¼ë¡œ ë°˜í™˜í•˜ëŠ” ì—”ë“œí¬ì¸íŠ¸"""
    log_file = "cos/response_time_log.json"

    try:
        with open(log_file, "r") as f:
            logs = json.load(f)

        timestamps = [log["timestamp"] for log in logs]
        response_times = [log["response_time"] for log in logs]

        # ì˜¤ë˜ëœ ìˆœìœ¼ë¡œ ì •ë ¬
        sorted_data = sorted(zip(timestamps, response_times))
        timestamps, response_times = zip(*sorted_data)

        return jsonify({"timestamps": timestamps, "response_times": response_times})

    except Exception as e:
        return jsonify({"error": f"Error loading response times: {str(e)}"})

