from flask import Blueprint, render_template, jsonify, request, session
import numpy as np
import re
from cos.word2vec_model import get_all_ingredients, model

visualization_bp = Blueprint("visualization", __name__)

@visualization_bp.route("/")
def visualization():
    return render_template("visualization.html")

# âœ… í…ìŠ¤íŠ¸ ê¸¸ì´ë¥¼ ì¤„ì´ëŠ” í•¨ìˆ˜ ì¶”ê°€
def truncate_text(text, max_length=15):
    return text if len(text) <= max_length else text[:max_length] + "â€¦"

# âœ… ê¸´ ì„±ë¶„ì„ ì ì ˆíˆ ë‚˜ëˆ„ëŠ” í† í¬ë‚˜ì´ì € í•¨ìˆ˜ ì¶”ê°€
def tokenize_text(text):
    # íŠ¹ìˆ˜ë¬¸ì ë° ë¶ˆí•„ìš”í•œ ë¬¸ì ì œê±°
    text = re.sub(r"[^ê°€-í£a-zA-Z0-9\s]", "", text)
    # ê³µë°± ê¸°ì¤€ìœ¼ë¡œ ë¶„í• í•˜ì—¬ ë‹¨ì–´ ë¦¬ìŠ¤íŠ¸ ìƒì„±
    tokens = text.split()
    # ë‹¨ì–´ê°€ ì—†ì„ ê²½ìš° ì›ë˜ í…ìŠ¤íŠ¸ ë°˜í™˜
    return tokens if tokens else [text]

# âœ… GETê³¼ POST ëª¨ë‘ ì§€ì› (POST: íŠ¹ì • ì„±ë¶„ ê²€ìƒ‰, GET: ì´ˆê¸° ë°ì´í„°)
@visualization_bp.route("/data", methods=["GET", "POST"])
def visualization_data():
    data = request.get_json() if request.method == "POST" else {}
    selected_ingredient = data.get("selected_ingredient", "").strip()

    print(f"ğŸ” [DEBUG] ìš”ì²­ëœ ì„±ë¶„: {selected_ingredient}")

    search_accuracy = session.get("search_accuracy", 0.0)
    recommendation_diversity = session.get("recommendation_diversity", 0.0)
    average_similarity = session.get("average_similarity", 0.0)

    all_ingredients = get_all_ingredients()
    input_ingredients = session.get("selected_ingredients", [])

    # âœ… í† í°í™”í•˜ì—¬ ê¸´ ì„±ë¶„ì„ ì ì ˆíˆ ë¶„í• 
    tokenized_selected_ingredient = tokenize_text(selected_ingredient) if selected_ingredient else []

    # âœ… íŠ¹ì • ì„±ë¶„ì´ ì…ë ¥ëœ ê²½ìš° í† í°í™”ëœ ì„±ë¶„ì„ ê¸°ì¤€ìœ¼ë¡œ ìœ ì‚¬í•œ ì„±ë¶„ 100ê°œ ê°€ì ¸ì˜¤ê¸°
    if tokenized_selected_ingredient and any(token in model.wv for token in tokenized_selected_ingredient):
        try:
            words = []
            for token in tokenized_selected_ingredient:
                if token in model.wv:
                    words.append(token)
                    words += [word for word, _ in model.wv.most_similar(token, topn=49)]  # ê° í† í°ì—ì„œ 49ê°œì”© ê°€ì ¸ì˜¤ê¸°
            words = list(set(words))[:100]  # ì¤‘ë³µ ì œê±° í›„ 100ê°œ ì œí•œ
        except KeyError:
            print(f"âŒ [ERROR] '{selected_ingredient}'ì˜ ì¼ë¶€ ë˜ëŠ” ì „ì²´ê°€ Word2Vec ëª¨ë¸ì— ì—†ìŒ!")
            return jsonify({"error": f"'{selected_ingredient}'ì˜ ì¼ë¶€ ë˜ëŠ” ì „ì²´ê°€ Word2Vec ëª¨ë¸ì— ì—†ìŠµë‹ˆë‹¤."}), 400
    else:
        words = all_ingredients[:100]

    # âœ… ëª¨ë¸ì—ì„œ ìœ íš¨í•œ ë²¡í„° ê°€ì ¸ì˜¤ê¸°
    valid_ingredients = [word for word in words if word in model.wv]

    if valid_ingredients:
        vectors = np.array([model.wv[word] for word in valid_ingredients])
    else:
        np.random.seed(42)
        vectors = np.random.rand(100, 3) * 100
        valid_ingredients = [f"ì„±ë¶„{i}" for i in range(100)]

    word2vec_x = vectors[:, 0].tolist()
    word2vec_y = vectors[:, 1].tolist()
    word2vec_z = vectors[:, 2].tolist()

    # âœ… ê¸´ ì„±ë¶„ëª…ì„ ì¤„ì—¬ì„œ í‘œì‹œ (Plotlyì— í‘œì‹œí•  ìš©ë„)
    shortened_labels = [truncate_text(word) for word in valid_ingredients]

    # âœ… ì¤‘ì‹¬ ì„±ë¶„ ìœ„ì¹˜ë¥¼ 3D ì¤‘ì‹¬ì— ë°°ì¹˜
    if selected_ingredient and any(token in valid_ingredients for token in tokenized_selected_ingredient):
        first_valid_token = next((token for token in tokenized_selected_ingredient if token in valid_ingredients), None)
        if first_valid_token:
            index = valid_ingredients.index(first_valid_token)
            word2vec_x.insert(0, word2vec_x.pop(index))
            word2vec_y.insert(0, word2vec_y.pop(index))
            word2vec_z.insert(0, word2vec_z.pop(index))
            shortened_labels.insert(0, shortened_labels.pop(index))

    return jsonify({
        "selected_ingredient": selected_ingredient,
        "search_accuracy": search_accuracy,
        "recommendation_diversity": recommendation_diversity,
        "average_similarity": average_similarity,
        "word2vec_x": word2vec_x,
        "word2vec_y": word2vec_y,
        "word2vec_z": word2vec_z,
        "word2vec_labels": shortened_labels,
        "hover_labels": valid_ingredients,
        "input_ingredients": input_ingredients
    })
